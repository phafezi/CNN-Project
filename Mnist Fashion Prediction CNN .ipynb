{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c040c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as t\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "\n",
    "#check that gpu is used for NN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a7b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_total = t.Compose([t.Grayscale(),\n",
    "                        t.ToTensor(),\n",
    "                        t.Normalize((0.5), (0.5)),\n",
    "                        t.Pad(6)])\n",
    "\n",
    "FashionData = datasets.MNIST(root = \"./\", train = True, download=False, transform=trans_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a602cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 40])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FashionData[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8843bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 42000.0 18000.0\n"
     ]
    }
   ],
   "source": [
    "FashionData_size = len(FashionData)\n",
    "train_size = FashionData_size * 0.7\n",
    "valid_size = FashionData_size - train_size\n",
    "print(FashionData_size, train_size, valid_size)\n",
    "train_set, valid_set = data.random_split(FashionData, [int(train_size), int(valid_size)], generator=torch.Generator().manual_seed(31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b074447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 40, 40]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch = next(iter(loader))\n",
    "images_batch, labels_batch = batch\n",
    "print(images_batch.shape, labels_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1e10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetWork, self).__init__()\n",
    "        # torch.nn has classes for every common deep learning layer:\n",
    "        # linear layers, convolutional layers, transformers, etc.\n",
    "        \n",
    "        \n",
    "        \n",
    "        #input Size : 40x40x1\n",
    "        #output Size : 19x19x16\n",
    "        #output width = (40 - 4)/2 + 1 =  19\n",
    "        self.conv1 = torch.nn.Conv2d(1,8, kernel_size = 4, stride = 2)\n",
    "        \n",
    "        #maxpooling \n",
    "        #input Size : 19x19x16\n",
    "        #output Size : 9x9x16        \n",
    "        #output width = (19 - 3)/2 + 1 =  9\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        \n",
    "        #input Size : 9x9x16\n",
    "        #output Size : 7x7x32\n",
    "        #output width = (9 - 3)/1 + 1 =  7\n",
    "        self.conv2 = torch.nn.Conv2d(8, 12, kernel_size = 3, stride = 1)\n",
    "        \n",
    "        #maxpooling \n",
    "        #input Size : 7x7x32\n",
    "        #output Size : 6x6x32        \n",
    "        #output width = (7 - 2)/1 + 1 =  6\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 1)\n",
    "        \n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(432, 128, bias=True) # defines a single linear layer\n",
    "        self.linear2 = torch.nn.Linear(128, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the Module.forward function is where you define how your network transforms input features to output\n",
    "        # predictions\n",
    "        \n",
    "        x = f.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        x = f.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.pool2(x)                \n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x,1 )\n",
    "        #print(x.shape)\n",
    "        x = f.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        #print(x.shape)                    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1795a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57726\n"
     ]
    }
   ],
   "source": [
    "net = NetWork()\n",
    "LR = 1e-3\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)\n",
    "\n",
    "optim = torch.optim.SGD(net.parameters(), lr=LR)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d1bc045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(2.2991, grad_fn=<NllLossBackward>)\n",
      "1\n",
      "tensor(2.2921, grad_fn=<NllLossBackward>)\n",
      "2\n",
      "tensor(2.2886, grad_fn=<NllLossBackward>)\n",
      "3\n",
      "tensor(2.2732, grad_fn=<NllLossBackward>)\n",
      "4\n",
      "tensor(2.2542, grad_fn=<NllLossBackward>)\n",
      "5\n",
      "tensor(2.2455, grad_fn=<NllLossBackward>)\n",
      "6\n",
      "tensor(2.2063, grad_fn=<NllLossBackward>)\n",
      "7\n",
      "tensor(2.1731, grad_fn=<NllLossBackward>)\n",
      "8\n",
      "tensor(2.1144, grad_fn=<NllLossBackward>)\n",
      "9\n",
      "tensor(1.9853, grad_fn=<NllLossBackward>)\n",
      "10\n",
      "tensor(1.7717, grad_fn=<NllLossBackward>)\n",
      "11\n",
      "tensor(1.4824, grad_fn=<NllLossBackward>)\n",
      "12\n",
      "tensor(1.1987, grad_fn=<NllLossBackward>)\n",
      "13\n",
      "tensor(0.9156, grad_fn=<NllLossBackward>)\n",
      "14\n",
      "tensor(0.9991, grad_fn=<NllLossBackward>)\n",
      "15\n",
      "tensor(0.6454, grad_fn=<NllLossBackward>)\n",
      "16\n",
      "tensor(0.7699, grad_fn=<NllLossBackward>)\n",
      "17\n",
      "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
      "18\n",
      "tensor(0.5670, grad_fn=<NllLossBackward>)\n",
      "19\n",
      "tensor(0.5657, grad_fn=<NllLossBackward>)\n",
      "20\n",
      "tensor(0.4454, grad_fn=<NllLossBackward>)\n",
      "21\n",
      "tensor(0.4928, grad_fn=<NllLossBackward>)\n",
      "22\n",
      "tensor(0.4046, grad_fn=<NllLossBackward>)\n",
      "23\n",
      "tensor(0.3575, grad_fn=<NllLossBackward>)\n",
      "24\n",
      "tensor(0.4454, grad_fn=<NllLossBackward>)\n",
      "25\n",
      "tensor(0.5458, grad_fn=<NllLossBackward>)\n",
      "26\n",
      "tensor(0.4425, grad_fn=<NllLossBackward>)\n",
      "27\n",
      "tensor(0.3342, grad_fn=<NllLossBackward>)\n",
      "28\n",
      "tensor(0.3735, grad_fn=<NllLossBackward>)\n",
      "29\n",
      "tensor(0.3202, grad_fn=<NllLossBackward>)\n",
      "30\n",
      "tensor(0.4333, grad_fn=<NllLossBackward>)\n",
      "31\n",
      "tensor(0.2780, grad_fn=<NllLossBackward>)\n",
      "32\n",
      "tensor(0.2472, grad_fn=<NllLossBackward>)\n",
      "33\n",
      "tensor(0.2688, grad_fn=<NllLossBackward>)\n",
      "34\n",
      "tensor(0.1729, grad_fn=<NllLossBackward>)\n",
      "35\n",
      "tensor(0.2734, grad_fn=<NllLossBackward>)\n",
      "36\n",
      "tensor(0.2632, grad_fn=<NllLossBackward>)\n",
      "37\n",
      "tensor(0.3275, grad_fn=<NllLossBackward>)\n",
      "38\n",
      "tensor(0.2367, grad_fn=<NllLossBackward>)\n",
      "39\n",
      "tensor(0.1486, grad_fn=<NllLossBackward>)\n",
      "40\n",
      "tensor(0.1916, grad_fn=<NllLossBackward>)\n",
      "41\n",
      "tensor(0.1599, grad_fn=<NllLossBackward>)\n",
      "42\n",
      "tensor(0.1642, grad_fn=<NllLossBackward>)\n",
      "43\n",
      "tensor(0.1461, grad_fn=<NllLossBackward>)\n",
      "44\n",
      "tensor(0.2825, grad_fn=<NllLossBackward>)\n",
      "45\n",
      "tensor(0.2245, grad_fn=<NllLossBackward>)\n",
      "46\n",
      "tensor(0.1462, grad_fn=<NllLossBackward>)\n",
      "47\n",
      "tensor(0.2568, grad_fn=<NllLossBackward>)\n",
      "48\n",
      "tensor(0.1082, grad_fn=<NllLossBackward>)\n",
      "49\n",
      "tensor(0.2346, grad_fn=<NllLossBackward>)\n",
      "50\n",
      "tensor(0.1631, grad_fn=<NllLossBackward>)\n",
      "51\n",
      "tensor(0.2067, grad_fn=<NllLossBackward>)\n",
      "52\n",
      "tensor(0.1713, grad_fn=<NllLossBackward>)\n",
      "53\n",
      "tensor(0.2689, grad_fn=<NllLossBackward>)\n",
      "54\n",
      "tensor(0.1528, grad_fn=<NllLossBackward>)\n",
      "55\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "56\n",
      "tensor(0.2228, grad_fn=<NllLossBackward>)\n",
      "57\n",
      "tensor(0.1543, grad_fn=<NllLossBackward>)\n",
      "58\n",
      "tensor(0.0555, grad_fn=<NllLossBackward>)\n",
      "59\n",
      "tensor(0.1274, grad_fn=<NllLossBackward>)\n",
      "60\n",
      "tensor(0.2358, grad_fn=<NllLossBackward>)\n",
      "61\n",
      "tensor(0.1852, grad_fn=<NllLossBackward>)\n",
      "62\n",
      "tensor(0.1907, grad_fn=<NllLossBackward>)\n",
      "63\n",
      "tensor(0.1436, grad_fn=<NllLossBackward>)\n",
      "64\n",
      "tensor(0.2130, grad_fn=<NllLossBackward>)\n",
      "65\n",
      "tensor(0.2274, grad_fn=<NllLossBackward>)\n",
      "66\n",
      "tensor(0.1106, grad_fn=<NllLossBackward>)\n",
      "67\n",
      "tensor(0.1161, grad_fn=<NllLossBackward>)\n",
      "68\n",
      "tensor(0.1766, grad_fn=<NllLossBackward>)\n",
      "69\n",
      "tensor(0.1540, grad_fn=<NllLossBackward>)\n",
      "70\n",
      "tensor(0.1185, grad_fn=<NllLossBackward>)\n",
      "71\n",
      "tensor(0.1742, grad_fn=<NllLossBackward>)\n",
      "72\n",
      "tensor(0.1065, grad_fn=<NllLossBackward>)\n",
      "73\n",
      "tensor(0.0998, grad_fn=<NllLossBackward>)\n",
      "74\n",
      "tensor(0.2253, grad_fn=<NllLossBackward>)\n",
      "75\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "76\n",
      "tensor(0.1351, grad_fn=<NllLossBackward>)\n",
      "77\n",
      "tensor(0.1263, grad_fn=<NllLossBackward>)\n",
      "78\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "79\n",
      "tensor(0.1615, grad_fn=<NllLossBackward>)\n",
      "80\n",
      "tensor(0.1635, grad_fn=<NllLossBackward>)\n",
      "81\n",
      "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
      "82\n",
      "tensor(0.1006, grad_fn=<NllLossBackward>)\n",
      "83\n",
      "tensor(0.1191, grad_fn=<NllLossBackward>)\n",
      "84\n",
      "tensor(0.0915, grad_fn=<NllLossBackward>)\n",
      "85\n",
      "tensor(0.1143, grad_fn=<NllLossBackward>)\n",
      "86\n",
      "tensor(0.0751, grad_fn=<NllLossBackward>)\n",
      "87\n",
      "tensor(0.1312, grad_fn=<NllLossBackward>)\n",
      "88\n",
      "tensor(0.1000, grad_fn=<NllLossBackward>)\n",
      "89\n",
      "tensor(0.2056, grad_fn=<NllLossBackward>)\n",
      "90\n",
      "tensor(0.1209, grad_fn=<NllLossBackward>)\n",
      "91\n",
      "tensor(0.0582, grad_fn=<NllLossBackward>)\n",
      "92\n",
      "tensor(0.1000, grad_fn=<NllLossBackward>)\n",
      "93\n",
      "tensor(0.1763, grad_fn=<NllLossBackward>)\n",
      "94\n",
      "tensor(0.1013, grad_fn=<NllLossBackward>)\n",
      "95\n",
      "tensor(0.0999, grad_fn=<NllLossBackward>)\n",
      "96\n",
      "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
      "97\n",
      "tensor(0.1468, grad_fn=<NllLossBackward>)\n",
      "98\n",
      "tensor(0.1283, grad_fn=<NllLossBackward>)\n",
      "99\n",
      "tensor(0.0273, grad_fn=<NllLossBackward>)\n",
      "100\n",
      "tensor(0.0809, grad_fn=<NllLossBackward>)\n",
      "101\n",
      "tensor(0.0896, grad_fn=<NllLossBackward>)\n",
      "102\n",
      "tensor(0.1223, grad_fn=<NllLossBackward>)\n",
      "103\n",
      "tensor(0.0956, grad_fn=<NllLossBackward>)\n",
      "104\n",
      "tensor(0.0861, grad_fn=<NllLossBackward>)\n",
      "105\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "106\n",
      "tensor(0.1874, grad_fn=<NllLossBackward>)\n",
      "107\n",
      "tensor(0.0482, grad_fn=<NllLossBackward>)\n",
      "108\n",
      "tensor(0.2095, grad_fn=<NllLossBackward>)\n",
      "109\n",
      "tensor(0.2737, grad_fn=<NllLossBackward>)\n",
      "110\n",
      "tensor(0.1176, grad_fn=<NllLossBackward>)\n",
      "111\n",
      "tensor(0.0771, grad_fn=<NllLossBackward>)\n",
      "112\n",
      "tensor(0.1063, grad_fn=<NllLossBackward>)\n",
      "113\n",
      "tensor(0.0962, grad_fn=<NllLossBackward>)\n",
      "114\n",
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "115\n",
      "tensor(0.0483, grad_fn=<NllLossBackward>)\n",
      "116\n",
      "tensor(0.1157, grad_fn=<NllLossBackward>)\n",
      "117\n",
      "tensor(0.0827, grad_fn=<NllLossBackward>)\n",
      "118\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "119\n",
      "tensor(0.0575, grad_fn=<NllLossBackward>)\n",
      "120\n",
      "tensor(0.0926, grad_fn=<NllLossBackward>)\n",
      "121\n",
      "tensor(0.1889, grad_fn=<NllLossBackward>)\n",
      "122\n",
      "tensor(0.1724, grad_fn=<NllLossBackward>)\n",
      "123\n",
      "tensor(0.0637, grad_fn=<NllLossBackward>)\n",
      "124\n",
      "tensor(0.0704, grad_fn=<NllLossBackward>)\n",
      "125\n",
      "tensor(0.0676, grad_fn=<NllLossBackward>)\n",
      "126\n",
      "tensor(0.1724, grad_fn=<NllLossBackward>)\n",
      "127\n",
      "tensor(0.2777, grad_fn=<NllLossBackward>)\n",
      "128\n",
      "tensor(0.1136, grad_fn=<NllLossBackward>)\n",
      "129\n",
      "tensor(0.0387, grad_fn=<NllLossBackward>)\n",
      "130\n",
      "tensor(0.1328, grad_fn=<NllLossBackward>)\n",
      "131\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "132\n",
      "tensor(0.0863, grad_fn=<NllLossBackward>)\n",
      "133\n",
      "tensor(0.0774, grad_fn=<NllLossBackward>)\n",
      "134\n",
      "tensor(0.1787, grad_fn=<NllLossBackward>)\n",
      "135\n",
      "tensor(0.0693, grad_fn=<NllLossBackward>)\n",
      "136\n",
      "tensor(0.1343, grad_fn=<NllLossBackward>)\n",
      "137\n",
      "tensor(0.0564, grad_fn=<NllLossBackward>)\n",
      "138\n",
      "tensor(0.1045, grad_fn=<NllLossBackward>)\n",
      "139\n",
      "tensor(0.0538, grad_fn=<NllLossBackward>)\n",
      "140\n",
      "tensor(0.0399, grad_fn=<NllLossBackward>)\n",
      "141\n",
      "tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "142\n",
      "tensor(0.0928, grad_fn=<NllLossBackward>)\n",
      "143\n",
      "tensor(0.1891, grad_fn=<NllLossBackward>)\n",
      "144\n",
      "tensor(0.0408, grad_fn=<NllLossBackward>)\n",
      "145\n",
      "tensor(0.1012, grad_fn=<NllLossBackward>)\n",
      "146\n",
      "tensor(0.0555, grad_fn=<NllLossBackward>)\n",
      "147\n",
      "tensor(0.0685, grad_fn=<NllLossBackward>)\n",
      "148\n",
      "tensor(0.2458, grad_fn=<NllLossBackward>)\n",
      "149\n",
      "tensor(0.0692, grad_fn=<NllLossBackward>)\n",
      "150\n",
      "tensor(0.0890, grad_fn=<NllLossBackward>)\n",
      "151\n",
      "tensor(0.0659, grad_fn=<NllLossBackward>)\n",
      "152\n",
      "tensor(0.0305, grad_fn=<NllLossBackward>)\n",
      "153\n",
      "tensor(0.0302, grad_fn=<NllLossBackward>)\n",
      "154\n",
      "tensor(0.0602, grad_fn=<NllLossBackward>)\n",
      "155\n",
      "tensor(0.0219, grad_fn=<NllLossBackward>)\n",
      "156\n",
      "tensor(0.1225, grad_fn=<NllLossBackward>)\n",
      "157\n",
      "tensor(0.0759, grad_fn=<NllLossBackward>)\n",
      "158\n",
      "tensor(0.0597, grad_fn=<NllLossBackward>)\n",
      "159\n",
      "tensor(0.1041, grad_fn=<NllLossBackward>)\n",
      "160\n",
      "tensor(0.0967, grad_fn=<NllLossBackward>)\n",
      "161\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "162\n",
      "tensor(0.1186, grad_fn=<NllLossBackward>)\n",
      "163\n",
      "tensor(0.0929, grad_fn=<NllLossBackward>)\n",
      "164\n",
      "tensor(0.0662, grad_fn=<NllLossBackward>)\n",
      "165\n",
      "tensor(0.0737, grad_fn=<NllLossBackward>)\n",
      "166\n",
      "tensor(0.0932, grad_fn=<NllLossBackward>)\n",
      "167\n",
      "tensor(0.0313, grad_fn=<NllLossBackward>)\n",
      "168\n",
      "tensor(0.0577, grad_fn=<NllLossBackward>)\n",
      "169\n",
      "tensor(0.0327, grad_fn=<NllLossBackward>)\n",
      "170\n",
      "tensor(0.0364, grad_fn=<NllLossBackward>)\n",
      "171\n",
      "tensor(0.0271, grad_fn=<NllLossBackward>)\n",
      "172\n",
      "tensor(0.0620, grad_fn=<NllLossBackward>)\n",
      "173\n",
      "tensor(0.0454, grad_fn=<NllLossBackward>)\n",
      "174\n",
      "tensor(0.0226, grad_fn=<NllLossBackward>)\n",
      "175\n",
      "tensor(0.0818, grad_fn=<NllLossBackward>)\n",
      "176\n",
      "tensor(0.0188, grad_fn=<NllLossBackward>)\n",
      "177\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "178\n",
      "tensor(0.0902, grad_fn=<NllLossBackward>)\n",
      "179\n",
      "tensor(0.2677, grad_fn=<NllLossBackward>)\n",
      "180\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0325, grad_fn=<NllLossBackward>)\n",
      "182\n",
      "tensor(0.0678, grad_fn=<NllLossBackward>)\n",
      "183\n",
      "tensor(0.1663, grad_fn=<NllLossBackward>)\n",
      "184\n",
      "tensor(0.0334, grad_fn=<NllLossBackward>)\n",
      "185\n",
      "tensor(0.1395, grad_fn=<NllLossBackward>)\n",
      "186\n",
      "tensor(0.0242, grad_fn=<NllLossBackward>)\n",
      "187\n",
      "tensor(0.1081, grad_fn=<NllLossBackward>)\n",
      "188\n",
      "tensor(0.0608, grad_fn=<NllLossBackward>)\n",
      "189\n",
      "tensor(0.0935, grad_fn=<NllLossBackward>)\n",
      "190\n",
      "tensor(0.0528, grad_fn=<NllLossBackward>)\n",
      "191\n",
      "tensor(0.0707, grad_fn=<NllLossBackward>)\n",
      "192\n",
      "tensor(0.0225, grad_fn=<NllLossBackward>)\n",
      "193\n",
      "tensor(0.0950, grad_fn=<NllLossBackward>)\n",
      "194\n",
      "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
      "195\n",
      "tensor(0.0625, grad_fn=<NllLossBackward>)\n",
      "196\n",
      "tensor(0.0546, grad_fn=<NllLossBackward>)\n",
      "197\n",
      "tensor(0.0327, grad_fn=<NllLossBackward>)\n",
      "198\n",
      "tensor(0.0886, grad_fn=<NllLossBackward>)\n",
      "199\n",
      "tensor(0.0759, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "val_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(epoch)\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        image_batch, lable_batch = batch\n",
    "        lablehat_batch = net(image_batch)\n",
    "\n",
    "        loss = loss_func(lablehat_batch, lable_batch)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # lr_scheduler.step()\n",
    "    \n",
    "    yhat_val = net(image_batch)\n",
    "    val_loss = loss_func(lablehat_batch, lable_batch)\n",
    "    val_losses.append(val_loss.detach().item())\n",
    "    print(val_loss)\n",
    "    if(val_loss < .01):\n",
    "        break;\n",
    "\n",
    "\n",
    "import os\n",
    "torch.save(net.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c793e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_val =  0.9754444444444444\n"
     ]
    }
   ],
   "source": [
    "correct = 0;\n",
    "\n",
    "valid_loader = data.DataLoader(valid_set, batch_size=int(valid_size), shuffle=False)\n",
    "for data_val_idx, data_val in enumerate(valid_loader):\n",
    "        image_data_val, lable_data_val = data_val\n",
    "        lablehat_data_val = net(image_data_val)\n",
    "        prediction = lablehat_data_val.argmax(dim=1)\n",
    "        \n",
    "        for i in range (int(valid_size)) :\n",
    "            if(prediction[i] == lable_data_val[i]):\n",
    "                correct = correct + 1\n",
    "print(\"acc_val = \", correct/valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f4b3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_val =  0.9769\n"
     ]
    }
   ],
   "source": [
    "correct = 0;\n",
    "FashionData_test = datasets.MNIST(root = \"./\", train = False, download=False, transform=trans_total)\n",
    "test_size = len(FashionData_test)\n",
    "test_loader = data.DataLoader(FashionData_test, batch_size=test_size, shuffle=False)\n",
    "for data_val_idx, data_val in enumerate(test_loader):\n",
    "        image_data_val, lable_data_val = data_val\n",
    "        lablehat_data_val = net(image_data_val)\n",
    "        prediction = lablehat_data_val.argmax(dim=1)\n",
    "\n",
    "        for i in range (test_size):\n",
    "            if(prediction[i] == lable_data_val[i]):\n",
    "                correct = correct + 1\n",
    "print(\"acc_val = \", correct/test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f397b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv-Gpu",
   "language": "python",
   "name": "pytorchenv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
